<html>
<head>
    <link rel="Stylesheet" type="text/css" href="style.css" />
    <title>Linear Algebra</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <script type="text/javascript" async src="https://cdn.jsdelivr.net/gh/mathjax/MathJax@2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
    <a href="index.html">Index</a>
    <hr>
    <div class="content">
    

<div id="Linear Algebra"><h1 id="Linear Algebra">Linear Algebra</h1></div>

<div id="Contents" class="toc"><h2 id="Contents">Contents</h2></div>
<ul>
<li>
<a href="Linear Algebra.html#Linear Algebra">Linear Algebra</a>

<ul>
<li>
<a href="Linear Algebra.html#Linear Algebra-Introduction">Introduction</a>

<ul>
<li>
<a href="Linear Algebra.html#Linear Algebra-Introduction-Linear Equations">Linear Equations</a>

<li>
<a href="Linear Algebra.html#Linear Algebra-Introduction-Matrix notation">Matrix notation</a>

<li>
<a href="Linear Algebra.html#Linear Algebra-Introduction-Reducing a matrix">Reducing a matrix</a>

<li>
<a href="Linear Algebra.html#Linear Algebra-Introduction-Vectors">Vectors</a>

</ul>
<li>
<a href="Linear Algebra.html#Linear Algebra-Solution sets of linear systems">Solution sets of linear systems</a>

<ul>
<li>
<a href="Linear Algebra.html#Linear Algebra-Solution sets of linear systems-Homogeneous linear systems">Homogeneous linear systems</a>

<li>
<a href="Linear Algebra.html#Linear Algebra-Solution sets of linear systems-Parametric vector form">Parametric vector form</a>

<li>
<a href="Linear Algebra.html#Linear Algebra-Solution sets of linear systems-Linear independence">Linear independence</a>

</ul>
<li>
<a href="Linear Algebra.html#Linear Algebra-Linear transformations">Linear transformations</a>

</ul>
</ul>

<div id="Linear Algebra-Introduction"><h2 id="Introduction">Introduction</h2></div>

<div id="Linear Algebra-Introduction-Linear Equations"><h3 id="Linear Equations">Linear Equations</h3></div>
<p>
"the study of linear equations"
</p>

<p>
a linear equation in the variables \(x_1, \dots, x_n\) has the form \(a_1 x_1+\dots+a_n x_n = b\), with \(a_1, \dots, a_n\) being the <em>coefficients</em>
</p>

<p>
geometric interpretation:
</p>

\[
\begin{alignat*}{3}
&amp;n=1\qquad &amp;&amp;a_1 x_1 = b \longrightarrow x_1 = \frac{b}{a_1}\qquad &amp;&amp;\text{(point on a line in $\Re$)}\\
&amp;n=2\qquad &amp;&amp;a_1 x_1 + a_2 x_2 = b \longrightarrow x_2 = \frac{b}{a_2} - \frac{a_1}{a_2}\qquad &amp;&amp;\text{(line in a plane in $\Re^2$)}\\
&amp;n=3\qquad &amp;&amp;a_1 x_1 + a_2 x_2 + a_3 x_3 = b\qquad &amp;&amp;\text{(planes in 3D space, in $\Re^3$)}
\end{alignat*}
\]

<p>
in general, \(n-1\)-dimensional planes in n-dimensional space
</p>

<p>
system of linear equations \(x_1, \dots, x_n\) is a collection of linear equations in these variables.
</p>

<p>
\(x_1 - 2x_2 = -1\)
</p>

<p>
\(-x_1 + 3x_2 = 3\)
</p>

<p>
If you graph them, you get this:
</p>

<p>
<img src="img-algebra/graph-example.png" alt="System of equations graph" />
</p>

<p>
the solution is the intersection.
</p>

<p>
a system of linear equations has:
</p>
<ol>
<li>
no solutions (inconsistent) -- e.g. parallel lines

<li>
exactly 1 solution (consistent)

<li>
infinitely many solutions (consistent) - e.g. the same line twice

</ol>

<p>
two linear systems are "equivalent" if they have the same solutions.
</p>

<div id="Linear Algebra-Introduction-Matrix notation"><h3 id="Matrix notation">Matrix notation</h3></div>
<table>
<tr>
<th>
Equation
</th>
<th>
(Augmented) coefficient matrix notation
</th>
</tr>
<tr>
<td>
\(\begin{alignat*}{6} &amp;x_1 &amp;&amp;-&amp;&amp;2x_2 &amp;&amp;+&amp;&amp;x_3 &amp;&amp;= 0\\ &amp; &amp;&amp; &amp;&amp;2x_2 &amp;&amp;-&amp;&amp;8x_3 &amp;&amp;= 8\\ &amp;5x_1 &amp;&amp; &amp;&amp; &amp;&amp;-&amp;&amp;5x_3 &amp;&amp;= 10\end{alignat*}\)
</td>
<td>
\(\begin{bmatrix} 1 &amp; -2 &amp; 1 &amp; 0\\ 0 &amp; 2 &amp; -8 &amp; 8\\ 5 &amp; 0 &amp; -5 &amp; 10 \end{bmatrix}\)
</td>
</tr>
</table>

<p>
the strategy to solve is to replace the system with an equivalent system that is easier to solve.
</p>

<p>
elementary row operations:
</p>
<ol>
<li>
replacement: add rows

<li>
scaling: multiply by constant (non-zero scalar)

<li>
interchange: swap two rows

</ol>

<p>
all of these are reversible &amp; don't change the solution set.
</p>

<p>
Matrices A and B are equivalent (\(A \sim B\)) if there is a sequence of elementary operations to transform A to B.
</p>

<p>
If augmented matrices of two systems are row-equivalent, then the systems are equivalent.
</p>

<p>
Matrix A is in echelon form if:
</p>
<ol>
<li>
zero rows are below non-zero rows

<li>
the leading entry of a row is contained in a column that is to the left of the leading entry of the row below it.

</ol>

<p>
A is in reduced echelon form if:
</p>
<ol>
<li>
A is in echelon form

<li>
all leading entries are 1

<li>
the leading entry is the only non-zero entry in that column

</ol>

<div id="Linear Algebra-Introduction-Reducing a matrix"><h3 id="Reducing a matrix">Reducing a matrix</h3></div>
<p>
The reduced echelon form of a matrix is unique.
</p>

<p>
every matrix is row-equivalent to a unique reduced echelon matrix.
</p>

<p>
the positions of the leading entries in an echelon matrix are unique
</p>

<p>
\(\begin{bmatrix} \textbf{1} &amp; * &amp; * &amp; *\\ 0 &amp; 0 &amp; \textbf{1} &amp; *\\ 0 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix}\)
</p>

<p>
the values in bold are pivot positions. the columns containing those values are pivot columns.
</p>

<p>
Row reduction algorithm:
</p>
<ol>
<li>
Start with leftmost non-zero column (pivot column)

<li>
Select a non-zero entry as pivot and move it to the pivot position.

<li>
Create zeros below the pivot position.

<li>
Ignore the row containing the pivot position &amp; repeat steps 1-3 until solved. The matrix will be in echelon form.

<li>
Make pivot positions equal to 1, create zeros in all pivot columns. Start with the rightmost column. The matrix will be in reduced echelon form.

</ol>

<p>
Side note: a computer chooses as pivot the entry that's smallest in absolute value to minimize the round-off error.
</p>

<p>
Basic variables correspond to pivot columns. Free variables correspond to non-pivot columns. You solve the equation by expressing basic variables in terms of free variables.
</p>

<p>
The matrix can be written in parametric form, example with \(x_3\) being a free variable:
</p>

<p>
\(\binom{x_1}{x_2} = \big\{ \binom{1}{4} + \binom{5}{-1} x_3 \;\rvert\; x_3 \in \Re \big\}\)
</p>

<p>
if there are any free variables, there are infinite solutions.
</p>

<div id="Linear Algebra-Introduction-Vectors"><h3 id="Vectors">Vectors</h3></div>
<p>
A vector is a line. If you have a vector in the form \(\begin{bmatrix} a\\b\end{bmatrix}\), you can draw it as an arrow from the origin ending at the point \((a,b)\).
</p>

<p>
To add vectors, add the individual cells together.
</p>

<p>
A vector equation \(a_1 x_1 + a_2 x_2 + \dots + a_n x_n = b\) has the same solution set as \(\begin{bmatrix} a_1 &amp; a_2 &amp; \dots &amp; a_n &amp; b \end{bmatrix}\).
</p>

<p>
When asked whether \(b\) is in \(\text{Span} \{v_1, \dots, v_p\}\), you have to check whether the augmented matrix \(\begin{bmatrix} v_1 &amp; \dots &amp; v_p &amp; b \end{bmatrix}\) has a solution.
</p>

<p>
\(b\) is a linear combination of \(A\) if \(Ax = b\) has a solution.
</p>

<p>
The span is the set of all linear combinations of the vectors.
</p>

<p>
To calculate \(Ax\), if the number of columns in A is the same as the number of rows in x, you can follow the definition:
</p>

\[
Ax = \begin{bmatrix} a_1 &amp; a_2 &amp; \dots &amp; a_n \end{bmatrix} \begin{bmatrix} x_1 \\ \dots \\ x_n \end{bmatrix} = x_1 a_1 + x_2 a_2 + \dots + x_n a_n
\]

<p>
You also have the rules (matrix A,  vectors u and v, scalar c):
</p>
<ul>
<li>
\(A(u+v) = Au + Av\)

<li>
\(A(cu) = c(Au)\)

</ul>

<div id="Linear Algebra-Solution sets of linear systems"><h2 id="Solution sets of linear systems">Solution sets of linear systems</h2></div>
<div id="Linear Algebra-Solution sets of linear systems-Homogeneous linear systems"><h3 id="Homogeneous linear systems">Homogeneous linear systems</h3></div>
<p>
homogeneous: if you can write it in \(Ax = 0\) where A is an \(m \times n\) matrix and 0 is the zero vector in \(\Re^m\)
</p>
<ul>
<li>
always has at least one solution (the trivial solution, \(x = 0\)).

<li>
has a nontrivial solution iff there is a free variable

<ul>
<li>
if the equation has only one free variable, the solution is a line through the origin

<li>
when there are two or more free variables, it's a line through the origin

</ul>
<li>
solution set is \(\text{Span} \{v_1, \ldots, v_p\}\) for suitable vectors

</ul>

<div id="Linear Algebra-Solution sets of linear systems-Parametric vector form"><h3 id="Parametric vector form">Parametric vector form</h3></div>
<p>
implicit description:
</p>
<ul>
<li>
a simple equation

<li>
e.g. \(10x_1 - 3x_2 - 2x_3 = 0\)

</ul>

<p>
explicit description (parametric vector form):
</p>
<ul>
<li>
the solution to the equation as a set spanned by u and v

<li>
of the form \(x = su + tv\), with \(s,t \in \Re\)

</ul>

<p>
the solution set of \(Ax = 0\) is \(x = tv\) with \(t \in \Re\).
</p>

<p>
if \(Ax = b\) has a solution, then you get the solution set by translating the solution set of \(Ax = 0\) using any particular solution p of \(Ax = b\). The set is then \(x = p + tv\)
</p>

<p>
Writing a solution set in parametric vector form:
</p>
<ol>
<li>
Row reduce augmented matrix to echelon form

<li>
Express each basic variable in terms of any free variables.

<li>
Write a typical solution x as a vector, with entries depending on the (potential) free variables.

<li>
Decompose x into a linear combination of vectors using free vars as parameters.

</ol>

<div id="Linear Algebra-Solution sets of linear systems-Linear independence"><h3 id="Linear independence">Linear independence</h3></div>

<p>
linearly independent:
</p>
<ul>
<li>
set of vector equations: iff the vector equation has only the trivial solution (\(x_1 = x_2 = x_3 = 0\))

<li>
columns of matrix: iff \(Ax = 0\) has <em>only</em> the trivial solution

<li>
one vector: iff v is not the zero vector

<li>
two vectors: if neither of the vectors is a multiple of the other

</ul>

<p>
linearly dependent:
</p>
<ul>
<li>
iff at least one of the vectors is a linear combination of the others

<li>
if there are more vectors than entries in each vector

<li>
if the set contains the zero vector

</ul>

<p>
a set is linearly dependent iff it's not linearly independent.
</p>

<div id="Linear Algebra-Linear transformations"><h2 id="Linear transformations">Linear transformations</h2></div>
<p>
definitions:
</p>
<ul>
<li>
transformation, function, mapping: rule assigning to each vector in \(\Re^n\) a vector \(T(x)\) in \(\Re^m\)

<li>
domain: set \(\Re^n\)

<li>
codomain: set \(\Re^m\)

<li>
image: vector T(x)

<li>
range: set of all images T(x)

</ul>

<p>
a projection transformation happens if you go to a lower dimension (e.g. \(x_3\) becomes 0). a shear transformation happens if a 2D square is tilted sideways into a parallelogram.
</p>

<p>
a transformation T is linear if:
</p>
<ol>
<li>
\(T(u + v) = T(u) + T(v)\) for all \(u,v \in \text{Domain}(T)\)

<li>
\(T(cu) = cT(u)\) for all scalars c and all \(u \in \text{Domain}(T)\)

</ol>

<p>
linear transformations preserve operations of vector addition and scalar multiplication.
</p>

<p>
if T is a linear transformation, then:
</p>
<ul>
<li>
\(T(0) = 0)\)

<li>
\(T(cu + dv) = cT(u) + dT(v)\)

<li>
\(T(c_1 v_2 + \dots + c_p v_p) = c_1 T(v_1) + \dots + c_p T(v_p)\) (superposition principle)

</ul>

<p>
given scalar r, and \(T: \Re^2 \rightarrow \Re^2\) by \(T(x) = rx\)
</p>
<ul>
<li>
contraction: when \(0 \leq r \leq 1\)

<li>
dilation: when \(r &gt; 1\)

</ul>

<p>
every linear transformation \(\Re^n \rightarrow \Re^m\) is a matrix transformation \(x \mapsto Ax\). 
</p>

<p>
\(A = [[T(e_1) \dots T(e_n)]\), where \(e_j\) is the jth column of the identity matrix in \(\Re^n\)
</p>

<p>
geometric linear transformations of \(\Re^2\):
</p>

<p>
<img src="img-algebra/geo-reflections.png" alt="Reflections" /> <img src="img-algebra/geo-contract-shears.png" alt="Contractions/expansions and shears" /> <img src="img-algebra/geo-projections.png" alt="Projections" />
</p>

<p>
types of mappings:
</p>
<ul>
<li>
\(T: \Re^n \rightarrow \Re^m\) is 'onto' \(\Re^m\) if <em>each</em> b in \(\Re^m\) is the image of <em>at least one</em> x in \(\Re^n\).

<li>
\(T: \Re^n \rightarrow \Re^m\) is one-to-one if <em>each</em> b in \(\Re^m\) is the image of <em>max one</em> x in \(\Re^n\).

<ul>
<li>
so if \(T(x) = 0\) only has the trivial solution

</ul>
</ul>

<p>
for mapping \(T: \Re^n \rightarrow \Re^m\) and standard matrix \(A\):
</p>
<ul>
<li>
T maps \(\Re^n\) onto \(\Re^m\) iff columns of matrix span \(\Re^m\)

<li>
T is one-to-one iff columns of matrix are linearly independent.

</ul>

    </div>
</body>
</html>
