<html>
<head>
    <link rel="Stylesheet" type="text/css" href="style.css" />
    <title>IS Lecture</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <script type="text/javascript" async src="https://cdn.jsdelivr.net/gh/mathjax/MathJax@2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
    <a href="index.html">Index</a>
    <hr>
    <div class="content">
    

<div id="Contents" class="toc"><h1 id="Contents">Contents</h1></div>
<ul>
<li>
<a href="IS Lecture.html#Intelligent Systems">Intelligent Systems</a>

<li>
<a href="IS Lecture.html#State Space Representations Intro">State Space Representations Intro</a>

<li>
<a href="IS Lecture.html#State space search">State space search</a>

<ul>
<li>
<a href="IS Lecture.html#State space search-Uninformed search strategies">Uninformed search strategies</a>

<li>
<a href="IS Lecture.html#State space search-Informed search (heuristics)">Informed search (heuristics)</a>

<li>
<a href="IS Lecture.html#State space search-Adversarial search">Adversarial search</a>

<li>
<a href="IS Lecture.html#State space search-Summary">Summary</a>

<li>
<a href="IS Lecture.html#State space search-Search direction">Search direction</a>

</ul>
<li>
<a href="IS Lecture.html#Rational agents">Rational agents</a>

<li>
<a href="IS Lecture.html#Logical agents">Logical agents</a>

<ul>
<li>
<a href="IS Lecture.html#Logical agents-What is logic">What is logic</a>

<li>
<a href="IS Lecture.html#Logical agents-Syntax">Syntax</a>

<li>
<a href="IS Lecture.html#Logical agents-Semantics">Semantics</a>

<li>
<a href="IS Lecture.html#Logical agents-Calculus (algorithms for inference)">Calculus (algorithms for inference)</a>

</ul>
<li>
<a href="IS Lecture.html#Probability and Uncertainty">Probability and Uncertainty</a>

<ul>
<li>
<a href="IS Lecture.html#Probability and Uncertainty-Vagueness: Fuzzy Set Theory">Vagueness: Fuzzy Set Theory</a>

<li>
<a href="IS Lecture.html#Probability and Uncertainty-Uncertainties: Probability Theory">Uncertainties: Probability Theory</a>

</ul>
<li>
<a href="IS Lecture.html#Assessment info">Assessment info</a>

</ul>

<div id="Intelligent Systems"><h1 id="Intelligent Systems">Intelligent Systems</h1></div>

<p>
core topics:
</p>
<ul>
<li>
search &amp; heuristics

<li>
knowledge

<li>
adaptivity

</ul>

<p>
<img src="/Users/alex/Dropbox/vimwiki/img/is/decision-making.png" alt="Decision making diagram" />
</p>

<div id="Intelligent Systems-Assessment info"><h2 id="Assessment info">Assessment info</h2></div>
<p>
check learning goals on canvas.
</p>

<p>
everything in working groups (this means go through the sheets again)
</p>
<ul>
<li>
informed search (DF, BF, DFID)

<li>
uninformed search (Hill Climbing, BF, A, A*)

<li>
adversarial search (minimax with alpha-beta)

<li>
logical representations

<li>
DPLL

<li>
uncertainty representations

<li>
Bayesian learning

<li>
NN/Deep learning

</ul>

<p>
research procedure
</p>
<ul>
<li>
take at least 4 bots you implemented

<li>
compare performance -- play against each other, in different environments

<li>
study results: outperforming, speed

<li>
define interesting hypotheses and research questions, use analysis to verify/falsify them

</ul>

<p>
scientific paper structure:
</p>
<ul>
<li>
title page with abstract

<ul>
<li>
title and authors

<li>
abstract of 2-3 paragraphs

</ul>
<li>
introduction: intro to problem, solution, some results (2 pages)

<li>
background info

<ul>
<li>
describe game, challenge, IS framework, whatever else is needed (1-2 pages)

</ul>
<li>
research question

<ul>
<li>
describe approach

<li>
what are:

<ul>
<li>
possible outcomes of setup and contribution

<li>
e.g. whether one method works, whether it works better than others

</ul>
<li>
also, define "working better"

</ul>
<li>
experimental setup (2 pages)

<ul>
<li>
explain how experiments were set up

<li>
what you did in terms of implementation

<li>
compare different methods

<li>
define metrics

</ul>
<li>
results (2 pages)

<ul>
<li>
describe results in overview tables

<li>
point reader to most significant, interesting results

</ul>
<li>
findings

<li>
conclusions

</ul>

<div id="State Space Representations Intro"><h1 id="State Space Representations Intro">State Space Representations Intro</h1></div>
<ul>
<li>
real world is complex, state space must be <em>abstracted</em> for problem solving

<ul>
<li>
abstract states map to sets of real states

<li>
abstract action maps to combination of real actions

<li>
abstract solution = set of real paths that are solutions in real world

</ul>
<li>
there may be multiple different state space representations

</ul>

<p>
Problem-solving agent uses this representation:
</p>
<ol>
<li>
what are actions to move between states?

<li>
what are appropriate states &amp; initial states?

<li>
what is the cost of an action?

<li>
goal: what are the successful world states?

<li>
search: determine possible sequences of actions leading to goal, choose 'best' sequence

<li>
execute: give solution, perform actions

</ol>

<p>
State space representation (example - vacuum cleaner):
</p>
<ul>
<li>
start with real-life problem

<li>
formulate abstract problem (states, actions)

<li>
formulate concrete (clean house) &amp; algorithmic goal (be in state 7 and 8)

<li>
find solution (sequence of actions to get to state 7 or 8)

<li>
execute plan (clean house according to abstract solution)

</ul>

<div id="State space search"><h1 id="State space search">State space search</h1></div>
<p>
How do we find the solutions of previous problems?
</p>
<ul>
<li>
search the state space

<li>
search through explicit tree generation: root is initial state, nodes/leaves generated through successor function

<li>
search generates a graph

</ul>

<p>
state: representation of a physical configuration
</p>

<p>
node: data structure in the search tree. it contains state, parent node, actions, etc.
</p>

<div id="State space search-Uninformed search strategies"><h2 id="Uninformed search strategies">Uninformed search strategies</h2></div>
<p>
strategy defines picking order of node expansion
</p>

<p>
uninformed methods: only use problem definition
</p>

<p>
informed methods: use heuristic function to estimate cost of solution
</p>

<p>
evaluating performance:
</p>
<ul>
<li>
does it always find a solution if there is one? (completeness)

<li>
does it find least-cost solution? (optimality)

<li>
how many nodes generated/expanded? (time complexity)

<li>
how many nodes are stored in memory during search? (space complexity)

<li>
complexity measured in terms of:

<ul>
<li>
b: max branching factor of search tree)

<li>
d: depth of least cost solution

<li>
m: max depth of state space, could be infinite

</ul>
<li>
time/space complexity measured in terms of max branching factor of search tree, depth of least cost solution, max depth of state space (could be infinite)

</ul>

<p>
<img src="/Users/alex/Dropbox/vimwiki/img/is/search-alg-summary.png" alt="Summary of uninformed search algorithms" />
</p>

<div id="State space search-Uninformed search strategies-Breadth-first (BF) search"><h3 id="Breadth-first (BF) search">Breadth-first (BF) search</h3></div>
<ul>
<li>
algorithm:

<ul>
<li>
expand shallowest unexpanded node

<li>
implementation - fringe (nodes that have to be explored) is a FIFO queue

</ul>
<li>
evaluation:

<ul>
<li>
completeness: yes, if branching factor b is finite

<li>
time complexity: if every state has b successors, and solution is at depth d, then \(O(b^{d+1})\) because of number of nodes generated

<li>
space complexity: shitty if every node has to be in memory - \(O(b^{d+1})\)

<li>
optimality: in general yes, unless actions have different cost

</ul>
<li>
memory requirements are bigger problem than execution time

</ul>

<div id="State space search-Uninformed search strategies-Depth-first (DF) search"><h3 id="Depth-first (DF) search">Depth-first (DF) search</h3></div>
<ul>
<li>
algorithm:

<ul>
<li>
expand deepest unexpanded node

<li>
implementation: fringe is a stack

</ul>
<li>
evaluation:

<ul>
<li>
completeness: no, unless search space is finite and no loops are possible

<li>
time complexity: shitty if m is larger than d (depth of optimal solution) -- \(O(b^m)\). but if many solutions, faster than BF

<li>
space complexity: backtracking search uses less memory, one successor instead of all b -- \(O(bm+1)\)

<li>
optimality: no, same issues as completeness

</ul>
</ul>

<div id="State space search-Uninformed search strategies-Depth-limited search"><h3 id="Depth-limited search">Depth-limited search</h3></div>
<ul>
<li>
DF-search with depth limit l (nodes at depth l have no successors)

<li>
solves infinite-path problem

<li>
evaluation:

<ul>
<li>
time: \(O(b^l)\)

<li>
space: \(O(bl)\)

<li>
completeness: not if l &lt; d

<li>
optimality: not if if l &gt; d

</ul>
</ul>

<div id="State space search-Uninformed search strategies-Iterative deepening search"><h3 id="Iterative deepening search">Iterative deepening search</h3></div>
<ul>
<li>
strategy to find best depth limit l

<li>
often used in combination with DF search

<li>
after each iteration, throw away everything and increase depth limit

<li>
combines benefits of DF (space complexity) and BF search (time complexity)

<li>
evaluation:

<ul>
<li>
completeness: yes (no infinite paths)

<li>
time: \(O(b^d)\)

<li>
space: \(O(bd)\)

</ul>
</ul>

<div id="State space search-Informed search (heuristics)"><h2 id="Informed search (heuristics)">Informed search (heuristics)</h2></div>

<p>
Heuristic function: "educated guess that reduces/limits search for solutions"
</p>

<p>
informedness property of heuristics:
</p>
<ul>
<li>
two heuristics \(h_1(n),\; h_2(n)\) with \(0 \leq h_1(n) \leq h_2(n) \leq h*(n)\)

<li>
then \(h_2(n)\) is more informed than \(h_1(n)\)

<li>
with \(h_1\) fewer nodes have to be searched with \(h_2\)

<li>
but \(h_2\) is often more expensive to calculate

<li>
perfect heuristics: \(h(n) = h*(n)\)

<li>
trivial heuristics: \(h(n) = 0\)

</ul>

<p>
Best-first search
</p>
<ul>
<li>
the general approach of informed search

<li>
node selected for expansion based on <em>evaluation function f(n)</em>

<li>
evaluation function measures distance to goal, choose node which appears best

<li>
fringe is queue in order of decreasing desirability

</ul>

<div id="State space search-Informed search (heuristics)-A Search"><h3 id="A Search">A Search</h3></div>
<p>
best-known form of best-first search
</p>

<p>
avoid expanding paths that are already expensive
</p>

<p>
evaluation function: \(f(n) = g(n) + h(n)\)
</p>
<ul>
<li>
g(n) the cost so far to reach node n

<li>
h(n) estimated cost to get from node n to goal

<li>
f(n) estimated total cost of path through node n to goal

</ul>

<div id="State space search-Informed search (heuristics)-A* Search"><h3 id="A* Search">A* Search</h3></div>

<p>
A search, but with an admissible heuristic
</p>
<ul>
<li>
heuristic is admissible if it <em>never</em> overestimates the cost to get to goal

<li>
admissible heuristics are optimistic

<li>
formally: \(h(n) \leq h*(n)\) where \(h*(n)\) is true cost from n to goal

</ul>

<p>
evaluation:
</p>
<ul>
<li>
complete: yes

<li>
time: exponential with path length

<li>
space: all nodes are stored

<li>
optimal: yes

</ul>

<div id="State space search-Adversarial search"><h2 id="Adversarial search">Adversarial search</h2></div>
<p>
search has no adversary, solution is a (heuristic) method for finding a goal
</p>

<p>
games have an adversary, solution is a strategy. time limits force an <em>approximate</em> solution.
</p>

<p>
you need a function to evaluate the "goodness" of a game position
</p>

<p>
types of games:
</p>

<table>
<tr>
<th>
&nbsp;
</th>
<th>
deterministic
</th>
<th>
chance
</th>
</tr>
<tr>
<td>
perfect information
</td>
<td>
chess, checkers, go, othello
</td>
<td>
backgammon, monopoly
</td>
</tr>
<tr>
<td>
imperfect information
</td>
<td>
&nbsp;
</td>
<td>
bridge poker, scrabble, nuclear war
</td>
</tr>
</table>

<div id="State space search-Adversarial search-Minimax"><h3 id="Minimax">Minimax</h3></div>

<div id="State space search-Adversarial search-Minimax-Setup"><h4 id="Setup">Setup</h4></div>
<p>
two players: MAX, MIN
</p>

<p>
MAX moves first, take turns until game is over. winner gets award, loser gets penalty.
</p>

<p>
how does this relate to search?
</p>
<ul>
<li>
initial state: game configuration e.g. with chess

<li>
successor function: list of &lt;move, state&gt; pairs with legal moves

<li>
terminal test: game finished?

<li>
utility function: numerical value of terminal states (win +1, lose -1, draw 0)

<li>
MAX uses search tree to determine next move

</ul>

<div id="State space search-Adversarial search-Minimax-Optimal strategies"><h4 id="Optimal strategies">Optimal strategies</h4></div>

<p>
find contingent strategy for MAX assuming infallible MIN.
</p>

<p>
assume that both players play optimally.
</p>

<p>
given game tree, optimal strategy can be found with minimax value of each node:
</p>
<blockquote>
minimax(n) = utility(n)                      if n is a terminal
minimax(max(successors of n))   if n is a max node
minimax(min(successors of n))   if n is a min node
</blockquote>

<div id="State space search-Adversarial search-Minimax-Evaluation"><h4 id="Evaluation">Evaluation</h4></div>
<ul>
<li>
complete: yes

<li>
time: \(O(b^m)\)

<li>
space: \(O(bm)\)

<li>
optimal: yes

</ul>

<div id="State space search-Adversarial search-Reducing problems of complexity with Minimax"><h3 id="Reducing problems of complexity with Minimax">Reducing problems of complexity with Minimax</h3></div>

<div id="State space search-Adversarial search-Reducing problems of complexity with Minimax-Cutting off search:"><h4 id="Cutting off search:">Cutting off search:</h4></div>
<p>
instead of <code>if TERMINAL(state) then return UTILITY(state)</code> do <code>if CUTOFF-TEST(state, depth) then return EVAL(state)</code>
</p>

<p>
this introduces fixed-limit depth. also loses completeness!
</p>

<p>
utility: value based on quality of state
</p>

<p>
heuristics: value based on estimation of quality of state
</p>

<p>
heuristic EVAL:
</p>
<ul>
<li>
produces estimate of expected utility of a game from a given position

<li>
should order terminal nodes in same way as utility

<li>
computation shouldn't take too long

</ul>

<div id="State space search-Adversarial search-Reducing problems of complexity with Minimax-Alpha-Beta pruning (efficient Minimax)"><h4 id="Alpha-Beta pruning (efficient Minimax)">Alpha-Beta pruning (efficient Minimax)</h4></div>

<p>
with minimax, the number of states is exponential to number of moves
</p>

<p>
so, don't examine every node and prune the subtrees you don't have to examine
</p>

<p>
Alpha: value of best MAX choice so far
</p>

<p>
Beta: value of best MIN choice so far
</p>

<p>
you prune the rest of the level if, at any point, beta &lt;= alpha.
</p>

<p>
pruning doesn't affect final results, entire subtrees can be pruned
</p>

<p>
good move ordering improves effectiveness of pruning
</p>

<p>
with 'perfect ordering', time complexity is: \(O(b^{m/2})\)
</p>

<div id="State space search-Adversarial search-Search with no or partial information"><h3 id="Search with no or partial information">Search with no or partial information</h3></div>

<p>
problems:
</p>
<ul>
<li>
contingency: percepts provide new info

<li>
exploration: when states/actions of environment are unknown

<li>
sensorless/conformant: agent may have no idea where it is

</ul>

<div id="State space search-Adversarial search-Search with no or partial information-Perfect information Monte Carlo sampling (`rdeep`)"><h4 id="Perfect information Monte Carlo sampling (`rdeep`)">Perfect information Monte Carlo sampling (<code>rdeep</code>)</h4></div>
<ol>
<li>
rollout:

<ul>
<li>
assume a belief state (with perfect info)

<li>
play random game in that state.

</ul>
<li>
average the rollouts

<li>
choose one with max average

</ol>

<div id="State space search-Adversarial search-Games with chance"><h3 id="Games with chance">Games with chance</h3></div>
<p>
<img src="/Users/alex/Dropbox/vimwiki/img/is/games-chance.png" alt="Games with chance" />
</p>

<div id="State space search-Summary (Schnapsen)"><h2 id="Summary (Schnapsen)">Summary (Schnapsen)</h2></div>
<p>
Phase 2: minimax &amp; alpha-beta pruning
</p>

<p>
Phase 1: PIMC sampling
</p>

<p>
what next? give the agent information about the game
</p>

<div id="State space search-Search direction"><h2 id="Search direction">Search direction</h2></div>
<p>
Data-driven: start with initial state (e.g. a maze)
</p>

<p>
Goal-driven: start with goal state, but has bigger branching factor (<span class="todo">TODO</span> confirm this)
</p>

<div id="Rational agents"><h1 id="Rational agents">Rational agents</h1></div>

<p>
"A rational agent chooses whichever action maximizes the expected value of the performance measure given the percept sequence to date and prior environment knowledge."
</p>

<div id="Rational agents-Agents"><h2 id="Agents">Agents</h2></div>
<p>
agent function maps percept sequence to actions (\(f: P* \rightarrow A\))
</p>

<p>
function is internally represented by agent program
</p>

<p>
program runs on physical architecture to produce f
</p>

<div id="Rational agents-Rationality"><h2 id="Rationality">Rationality</h2></div>
<p>
what is rational at a specific time depends on:
</p>
<ul>
<li>
expected value of performance measure -- heuristics

<li>
actions and choices -- search

<li>
percept sequence to date -- learning

<li>
prior environment-- KR

</ul>

<p>
rationality is not omniscience or perfection
</p>

<div id="Rational agents-Task environments"><h2 id="Task environments">Task environments</h2></div>

<p>
to design rational agent, we must specify environment (PEAS):
</p>
<ul>
<li>
performance: safety, destination, profits, legality, comfort

<li>
environment: streets, traffic, pedestrians, weather

<li>
actuators: steering, accelerating, brake, horn, speaker/display

<li>
sensors: video, sonar, speedometer, etc.

</ul>

<p>
environment types:
</p>
<ul>
<li>
observable: fully (can detect all relevant aspects with sensors) or partially

<li>
deterministic: (yes or no)

<li>
static: (yes, no, semi)

<li>
discrete: (yes or no)

<li>
single-agent: (yes or no)

</ul>

<p>
<img src="/Users/alex/Dropbox/vimwiki/img/is/environment-types.png" alt="Environment types table" />
</p>

<p>
For Schnapsen:
</p>
<ul>
<li>
observable: not fully

<li>
deterministic: yes

<li>
static: yes

<li>
discrete: yes

<li>
single-agent: no

</ul>

<div id="Rational agents-Agent types"><h2 id="Agent types">Agent types</h2></div>

<div id="Rational agents-Agent types-Simple Reflex"><h3 id="Simple Reflex">Simple Reflex</h3></div>
<p>
select action on basis of <em>only the current percept</em>
</p>

<p>
large reduction in possible percept/action situations
</p>

<p>
implemented using condition-action rules
</p>

<p>
only works if environment is fully observable, otherwise may result in infinite loops.
</p>

<div id="Rational agents-Agent types-Reflex &amp; State"><h3 id="Reflex &amp; State">Reflex &amp; State</h3></div>
<p>
to tackle partially observable environments, maintain internal state
</p>

<p>
over time, update state using world knowledge.
</p>

<div id="Rational agents-Agent types-Goal-Based"><h3 id="Goal-Based">Goal-Based</h3></div>
<p>
agent needs a goal to know the desirable situations
</p>

<p>
future is taken into account
</p>

<div id="Rational agents-Agent types-Learning"><h3 id="Learning">Learning</h3></div>
<p>
teach agents instead of instructing them
</p>

<p>
very robust toward initially unknown environments.
</p>

<div id="Logical agents"><h1 id="Logical agents">Logical agents</h1></div>

<div id="Logical agents-What is logic"><h2 id="What is logic">What is logic</h2></div>
<p>
logic: generic method to deal with partial/imperfect/implicit information
</p>

<p>
we need:
</p>
<ul>
<li>
syntax to write statement about rules &amp; knowledge of the game (a language)

<li>
semantics to say what legal expressions mean, the meaning of each sentence with respect to interpretations

<li>
calculus for how to determine meaning for legal expressions

</ul>

<p>
knowledge-based/logical agents must be able to:
</p>
<ul>
<li>
represent states &amp; actions

<li>
incorporate new percepts, update internal representation of world

<li>
deduce hidden properties of the world &amp; appropriate actions

</ul>

<p>
online/exploratory search: go to position, evaluate all options, possibly look ahead. have to re-evaluate current position.
</p>

<div id="Logical agents-Syntax"><h2 id="Syntax">Syntax</h2></div>
<div id="Logical agents-Syntax-Propositional logic (PL)"><h3 id="Propositional logic (PL)">Propositional logic (PL)</h3></div>
<p>
assumes world contains facts
</p>

<p>
uses proposition symbols to state these facts.
</p>

<p>
pros:
</p>
<ul>
<li>
declarative

<li>
allows partial/disjunctive/negated information

<li>
is compositional

<li>
meaning of statements is context-independent

</ul>

<p>
cons:
</p>
<ul>
<li>
very limited expressive power

</ul>

<div id="Logical agents-Syntax-First order logic (FOL)"><h3 id="First order logic (FOL)">First order logic (FOL)</h3></div>
<p>
an extension of propositional logic.
</p>

<p>
allows variables to range over atomic symbols in the domain.
</p>

<p>
assumes world contains:
</p>
<ul>
<li>
objects: people, houses, colors, baseball games, etc.

<li>
relations: red, round, prime, brother of, comes between, bigger than, etc.

<li>
functions: father of, best friend, one more than, plus, etc.  

</ul>

<div id="Logical agents-Syntax-First order logic (FOL)-Basic elements:"><h4 id="Basic elements:">Basic elements:</h4></div>
<ul>
<li>
Constants: KingJohn, 2, UCB, ...

<li>
Predicates: Brother, &gt;, ...

<li>
Functions: Sqrt, LeftLegOf, ...

<li>
Variables: x, y, ...

<li>
Connectives: ∧, ∨, ¬, ⇒, ⇔

</ul>

<div id="Logical agents-Syntax-First order logic (FOL)-Sentences"><h4 id="Sentences">Sentences</h4></div>
<pre>
Atomic sentence = predicate (term_1,..., term_n)
                  or term_1 = term_2
Term = function(term_1,..., term_n)
      or constant 
      or variable
</pre>

<p>
Complex sentences are made from atomic sentences using connectives.
</p>

<div id="Logical agents-Syntax-First order logic (FOL)-Quantification"><h4 id="Quantification">Quantification</h4></div>
<div id="Logical agents-Syntax-First order logic (FOL)-Quantification-Universal quantification"><h5 id="Universal quantification">Universal quantification</h5></div>
<p>
∀ &lt;variables&gt; &lt;sentence&gt;
</p>

<p>
∀x P is true in a model <em>m</em> iff P is true with x being each possible object in the model
</p>

<p>
(you can roughly translate that to conjunctions) 
</p>

<p>
typically used with ⇒
</p>

<p>
<span id="Logical agents-Syntax-First order logic (FOL)-Quantification-Universal quantification-CARE:"></span><strong id="CARE:">CARE:</strong> ∀x ∀y ≠ ∀y ∀x
</p>

<div id="Logical agents-Syntax-First order logic (FOL)-Quantification-Existential quantification"><h5 id="Existential quantification">Existential quantification</h5></div>
<p>
∃ &lt;variables&gt; &lt;sentence&gt;
</p>

<p>
∃x P is true in a model <em>m</em> iff P is true with x being some possible object in the model
</p>

<p>
(you can roughly translate that to disjunction of instantiations of P)
</p>

<p>
typically used with ∧
</p>

<p>
watch out, if you use it with ⇒, it works even if the LHS is false!
</p>

<p>
<span id="Logical agents-Syntax-First order logic (FOL)-Quantification-Existential quantification-CARE"></span><strong id="CARE">CARE</strong>: ∃x ∃y ≠ ∃y ∃x
</p>

<div id="Logical agents-Syntax-First order logic (FOL)-Quantification-Quantifier Duality"><h5 id="Quantifier Duality">Quantifier Duality</h5></div>
<p>
each quantifier can be expressed in terms of the other
</p>

<p>
e.g. these are the same:
</p>
<ul>
<li>
∀x Likes(x, IceCream) -- "everyone likes ice cream"

<li>
¬∃x ¬Likes(x, IceCream) -- "there is nobody who doesn't like ice cream"

</ul>

<div id="Logical agents-Syntax-First order logic (FOL)-Decidability vs undecidability"><h4 id="Decidability vs undecidability">Decidability vs undecidability</h4></div>
<p>
undecidability
</p>
<ul>
<li>
Turing machine can calculate everything that can be calculated

<li>
halting problem: \(K := { (i,x) | \text{program i halts when run on input x})\)

</ul>

<p>
decidability
</p>
<ul>
<li>
validity of FOL is not decidable (but semi-decidable)

<li>
if a theorem is logically entailed by an axiom, you can prove that it is.

<li>
if not, you can't necessarily prove that it's not (because you can continue with your proof infinitely).

</ul>

<div id="Logical agents-Syntax-First order logic (FOL)-Knowledge engineering in FOL"><h4 id="Knowledge engineering in FOL">Knowledge engineering in FOL</h4></div>
<ol>
<li>
Identify the task

<li>
Assemble relevant knowledge

<li>
Decide on vocabulary of predicates, functions, and constants

<li>
Encode general knowledge about the domain (terms that we want to use)

<li>
Encode description of the specific problem instance

<li>
Pose queries to the inference procedure and get answers

</ol>

<div id="Logical agents-Syntax-Choice of formalisms"><h3 id="Choice of formalisms">Choice of formalisms</h3></div>
<p>
first-order logic: represents knowledge
</p>

<p>
propositional logic: used for reasoning ("propositionalisation")
</p>

<p>
then use reasoner to check for entailment of propositional logic knowledge base an decision query
</p>
<ul>
<li>
Davis Putnam (DPLL) algorithm

<li>
formulas have to be in clause normal form (CNF)

<li>
calculus is proof by refutation:

<ul>
<li>
DPLL determines satisfiability of a KB

<li>
entailment of KB |= a by "refutation":

<ul>
<li>
KB |= a if KB ∩ {~a} is unsatisfiable

<li>
assume the opposite and prove it's impossible

</ul>
</ul>
</ul>

<div id="Logical agents-Syntax-Propositionalising FOL"><h3 id="Propositionalising FOL">Propositionalising FOL</h3></div>
<div id="Logical agents-Syntax-Propositionalising FOL-Reduction to propositional inference"><h4 id="Reduction to propositional inference">Reduction to propositional inference</h4></div>
<p>
every FOL KB can be propositionalised so as to preserve entailment
</p>

<p>
if a sentence α is entailed by an FOL KB, it is entailed by a <em>finite</em> subset of the propositionalised KB
</p>

<div id="Logical agents-Syntax-Propositionalising FOL-Universal instantiation (UI):"><h4 id="Universal instantiation (UI):">Universal instantiation (UI):</h4></div>
<p>
every instantiation of a universally quantified sentence is entailed by it.
</p>

<p>
<img src="/Users/alex/Dropbox/vimwiki/img/is/univ-instant.png" alt="Universal instantiation" />
</p>

<p>
example:
</p>
<pre>
∀x King(x) ∧ Greedy(x) ⇒ Evil(x)
King(John) ∧ Greedy(John) ⇒ Evil(John)
etc.
</pre>

<div id="Logical agents-Syntax-Propositionalising FOL-Existential instantiation (EI):"><h4 id="Existential instantiation (EI):">Existential instantiation (EI):</h4></div>
<p>
<img src="/Users/alex/Dropbox/vimwiki/img/is/exist-instant.png" alt="Existential instantiation" />
</p>

<p>
example:
</p>
<pre>
∃x Crown(x) ∧ OnHead(x,John)
Crown(C_1) ∧ OnHead(C_1, John)
</pre>

<div id="Logical agents-Syntax-Propositionalising FOL-Applying in Schnapsen - Strategies (examples)"><h4 id="Applying in Schnapsen - Strategies (examples)">Applying in Schnapsen - Strategies (examples)</h4></div>
<div id="Logical agents-Syntax-Propositionalising FOL-Applying in Schnapsen - Strategies (examples)-Play Jack"><h5 id="Play Jack">Play Jack</h5></div>

<p>
check whether card is a jack: 
</p>

<pre>
KB |= PlayJack(x) ?
</pre>

<p>
represent strategy: 
</p>

<pre>
∀x PlayJack(x) ⇔ Jack(x)
</pre>

<p>
represent game information: 
</p>

<pre>
KB = {Jack(4), Jack(0), Jack(14), Jack(19)}
</pre>

<div id="Logical agents-Syntax-Propositionalising FOL-Applying in Schnapsen - Strategies (examples)-Play cheap"><h5 id="Play cheap">Play cheap</h5></div>
<p>
only play Jacks: check whether card is cheap
</p>

<pre>
KB |= PlayCheap(x) ?
</pre>

<p>
represent strategy:
</p>

<pre>
∀x PlayCheap(x) ⇔ Jack(x) ∨ Queen(x) ∨ King(x)
</pre>
  
<p>
represent game information:
</p>

<pre>
KB = {Jack(4), Jack(9), Jack(14), Jack(19), Queen(5), ...}
</pre>
  
<div id="Logical agents-Syntax-Propositionalising FOL-Applying in Schnapsen - Strategies (examples)-Play trump marriage"><h5 id="Play trump marriage">Play trump marriage</h5></div>
<pre>
TrumpMarriage(x) ⇔ Q(x) &amp; Trump(x) &amp; ∃y: SameColor(x,y) &amp; K(y) &amp; MyCard(y)
SameColor(x,y) ⇔ (C(x) &amp; C(y)) ∨ (D(x) &amp; D(y)) ∨ (H(x) &amp; H(y)) ∨ (S(x) &amp; S(y))
</pre>

<div id="Logical agents-Semantics"><h2 id="Semantics">Semantics</h2></div>
<div id="Logical agents-Semantics-Interpretations &amp; Models"><h3 id="Interpretations &amp; Models">Interpretations &amp; Models</h3></div>
<p>
interpretation: assignment of meaning to symbols of formal language
</p>

<p>
model: interpretation that satisfies defining axioms of knowledge base
</p>

<p>
<em>m</em> is a model of a sentence <em>α</em> if <em>α</em> holds in <em>m</em>.
</p>

<p>
M(a) is the set of all models of a.
</p>

<p>
each model specifies true/false for each proposition symbol (∧, ∨, ¬, ⇒, ⇐, ⇔)
</p>

<div id="Logical agents-Semantics-Entailment"><h3 id="Entailment">Entailment</h3></div>
<p>
the knowledge base (KB) entails <em>α</em>: <em>α</em> follows from the information in the knowledge base (KB |= <em>α</em>)
</p>

<p>
KB entails <em>α</em> iff <em>α</em> holds in all worlds where KB is true.
</p>

<p>
a knowledge base is the rules + observations.
</p>

<p>
a sentence is:
</p>
<ul>
<li>
entailed by KB iff α holds in all models of KB

<li>
valid if it is true in all models

<li>
satisfiable  if it is true in some model

<li>
unsatisfiable if it is true in no models

</ul>

<p>
two statements are logically equivalent if they are true in same set of models:
</p>

<p>
α ≡ β iff α |= β and β |= α
</p>

<div id="Logical agents-Semantics-Truth"><h3 id="Truth">Truth</h3></div>
<p>
sentences are true with respect to model and interpretation.
</p>

<p>
model contains objects and relations among them
</p>

<p>
interpretation specifies referents for:
</p>
<ul>
<li>
constant symbols -- objects

<li>
predicate symbols -- relations

<li>
function symbols -- functional relations

</ul>

<p>
an atomic sentence \(predicate(term_1, ..., term_n)\) is true
iff the objects referred to by \(term_1,..., term_n\)
are in the relation referred to by \(predicate\)
</p>

<div id="Logical agents-Semantics-Validity"><h3 id="Validity">Validity</h3></div>
<p>
valid if it is true in all models.
</p>

<p>
e.g. True, A ∨ ¬A, A ⇒ A, (A ∧ (A e.g. True, A ∨ ⇒ B)) ⇒ B)
</p>

<div id="Logical agents-Semantics-Satisfiability"><h3 id="Satisfiability">Satisfiability</h3></div>
<ul>
<li>
satisfiable if it is true in <em>some</em> model

<li>
unsatisfiable if it is true in <em>no</em> models

</ul>

<div id="Logical agents-Calculus (algorithms for inference)"><h2 id="Calculus (algorithms for inference)">Calculus (algorithms for inference)</h2></div>
<div id="Logical agents-Calculus (algorithms for inference)-Properties of inference"><h3 id="Properties of inference">Properties of inference</h3></div>
<p>
sound: if an algorithm \(|-\) only derives entailed sentences. 
  i.e. if KB \(|-\) α also KB |= α
</p>

<p>
complete: if an algorithm derives any sentence that is entailed. 
  i.e. KB |= α implies KB |- α
</p>

<p>
a calculus terminates if it finds entailed sentences in finite time.
</p>

<p>
a logic is <em>decidable</em> if there is <em>sound and complete</em> calculus that <em>terminates</em>.
</p>

<div id="Logical agents-Calculus (algorithms for inference)-Proof methods"><h3 id="Proof methods">Proof methods</h3></div>
<ol>
<li>
Model checking and search

<ul>
<li>
truth table enumeration (exponential in n)

<li>
improved backtracking (DPLL)

<li>
heuristics for choosing right order

</ul>
<li>
application of inference rules

<ul>
<li>
sound generation of new sentences from old

<li>
proof = sequence of rule applications (actions)

</ul>
</ol>

<div id="Logical agents-Calculus (algorithms for inference)-Proof methods-Model checking &amp; search"><h4 id="Model checking &amp; search">Model checking &amp; search</h4></div>
<div id="Logical agents-Calculus (algorithms for inference)-Proof methods-Model checking &amp; search-Truth Tables for inference"><h5 id="Truth Tables for inference">Truth Tables for inference</h5></div>
<p>
enumerate interpretations and check that where KB is true, α is true.
</p>

<table>
<tr>
<th>
\(fact_1\)
</th>
<th>
\(fact_2\)
</th>
<th>
\(fact_3\)
</th>
<th>
\(KB\)
</th>
<th>
\(α\)
</th>
</tr>
<tr>
<td>
false
</td>
<td>
false
</td>
<td>
false
</td>
<td>
false
</td>
<td>
true
</td>
</tr>
<tr>
<td>
false
</td>
<td>
false
</td>
<td>
false
</td>
<td>
false
</td>
<td>
true
</td>
</tr>
<tr>
<td>
false
</td>
<td>
true
</td>
<td>
false
</td>
<td>
<em>true</em>
</td>
<td>
<em>true</em>
</td>
</tr>
</table>

<p>
algorithm:
</p>

<pre>
for (m in truth assignments) {
  if (m makes F true) return "satisfiable"
}
return "unsatisfiable"
</pre>

<div id="Logical agents-Calculus (algorithms for inference)-Proof methods-Model checking &amp; search-Effective proofs by model checking"><h5 id="Effective proofs by model checking">Effective proofs by model checking</h5></div>

<p>
Clever search (depth first, redundancy, heuristics)
</p>

<p>
Two families of efficient algorithms for propositional inference based on model checking
</p>
<ul>
<li>
complete backtracking search algorithms -- DPLL (Davis, Putnam, Logemann, Loveland)

<li>
incomplete local search algorithm (WalkSAT algorithm)

</ul>

<div id="Logical agents-Calculus (algorithms for inference)-Proof methods-Model checking &amp; search-Clause Normal Form (CNF)"><h5 id="Clause Normal Form (CNF)">Clause Normal Form (CNF)</h5></div>

<p>
memo technique: the C in CNF for <em>conjunction</em> normal form
</p>

<p>
A PL formula is in CNF if it is a conjunction of disjunctions of literals.
</p>
<ul>
<li>
e.g.: {{a,b}, {~a, c}, {~b, c}}

<li>
equivalent to (a ∨ b) ∧ (~ a ∨ c) ∧ (~ b ∨ c)

</ul>

<p>
calculating CNF:
</p>
<ol>
<li>
Remove implications: 

<ul>
<li>
(p ⇔ q) to ((p ⇒ q) ∧ (q ⇒ p))

<li>
(p → q) to (¬ p ∨ q)

</ul>
<li>
Move negations inward: 

<ul>
<li>
¬ (p ∨ q) to (¬ p ∧ ¬ q)

<li>
¬ (p ∧ q) to (¬ p ∨ ¬ q)

</ul>
<li>
Move conjunctions outward:

<ul>
<li>
(r ∨ (p ∧ q)) to ((r ∨ p) ∧ (r ∨ q))

</ul>
<li>
Split up conjunctive clauses:

<ul>
<li>
( (p1 ∨ p2) ∧ (q1 ∨ q2) ) to (p1 ∨ p2), (q1 ∨ q2)

</ul>
</ol>

<div id="Logical agents-Calculus (algorithms for inference)-Proof methods-Model checking &amp; search-DPLL algorithm"><h5 id="DPLL algorithm">DPLL algorithm</h5></div>

<p>
when you have CNF, you can run the DPLL algorithm. determines if propositional logic sentence in CNF is satisfiable.
</p>

<p>
returns true if F is satisfiable, false otherwise.
</p>

<p>
basically assign values until contradiction, then backtrack.
</p>

<p>
Improving DPLL:
</p>
<ul>
<li>
if a literal in a disjunction clause is true, the clause is true

<li>
if a literal in a disjunction clause is false, the literal can be removed

<li>
if a clause is empty, it is false

<li>
a unit literal has to be true

<li>
a pure literal (only appears non-negated) has to be true

</ul>

<p>
the algorithm:
</p>

<pre>
dpll (F, literal) {
  remove clauses containing literal
  shorten clauses containing ¬literal
  if (F contains no clauses) 
    return true
  if (F contains empty clause) 
    return false
  if (F contains a unit or pure literal)
    return dpll(F, literal)
  
  choose P in F
  if (dpll(F, ¬P)) 
    return true
  
  return dpll(F, P)
}
</pre>

<div id="Logical agents-Calculus (algorithms for inference)-Proof methods-Model checking &amp; search-DPLL algorithm-Heuristic search in DPLL"><h6 id="Heuristic search in DPLL">Heuristic search in DPLL</h6></div>

<p>
used in DPLL to select proposition for branching
</p>

<p>
idea: identify most constrained variable, likely to create many unit clauses
</p>

<p>
MOM's heuristic: most occurrences in clauses of minimum length
</p>

<p>
why is it better than truth table enumeration?
</p>
<ul>
<li>
early termination: clause is true if any literal is true. sentence is false if any clause is false.

<li>
pure symbol heuristic: always appears with the same sign in all clauses, has to be true

<li>
unit clause heuristic: only one literal in the clause, so it must be true

</ul>

<p>
proving entailment KB |= a by refutation:
</p>
<ol>
<li>
translate KB into CNF to get cnf(KB)

<li>
translate ~a into CNF to get cnf(~a)

<li>
add cnf(~a) to cnf(KB)

<li>
apply DPLL until either satisfiable (model is found) or unsatisfiable (search exhausted)

<li>
if satisfiable, not entailed. otherwise, entailed.

</ol>

<div id="Logical agents-Calculus (algorithms for inference)-Proof methods-Model checking &amp; search-Satisfiability modulo theory"><h5 id="Satisfiability modulo theory">Satisfiability modulo theory</h5></div>

<p>
Boolean satisfiability (SAT): is there an assignment to the \(p_1, p_2, ..., p_n\) variables such that \(\phi\) evaluates to 1?
</p>

<p>
<img src="/Users/alex/Dropbox/vimwiki/img/is/boolean-satisfiability.png" alt="Boolean satisfiability diagram" />
</p>

<p>
SAT vs SMT:
</p>
<ul>
<li>
SMT (satisfiability modulo theories) extend SAT solving by adding extensions.

<li>
SMT solver can solve SAT problem, but not vice-versa.

<li>
SMT is used in analog circuit verification, RTL, verification, and card games.

</ul>

<p>
SMT theories:
</p>
<ul>
<li>
real or integer arithmetic

<li>
equality and uninterpreted functions

<li>
bit vectors and arrays

<li>
properties:

<ul>
<li>
decidable: an effective procedure exists to determine if formula is member of theory T

<li>
often quantifier-free

</ul>
<li>
core theory:

<ul>
<li>
type boolean

<li>
constants {TRUE, FALSE}

<li>
functions {AND, OR, XOR, =&gt;}

</ul>
<li>
integer theory:

<ul>
<li>
type int

<li>
all numerals are int constants

<li>
functions {+, -, x, mod, div, abs}

</ul>
<li>
reals theory:

<ul>
<li>
type real

<li>
functions {+, -, x, /, &lt;, &gt;}

<li>


</ul>
</ul>
<div id="Logical agents-Calculus (algorithms for inference)-Proof methods-Rule-based reasoning"><h4 id="Rule-based reasoning">Rule-based reasoning</h4></div>
<div id="Logical agents-Calculus (algorithms for inference)-Proof methods-Rule-based reasoning-Inference rules"><h5 id="Inference rules">Inference rules</h5></div>
<p>
inference rule: logical form consisting of function taking premises, analyzing their syntax, and returning one or more conclusions
</p>

<p>
Modens Ponens: \(\frac{\alpha\implies\beta,\;\alpha}{\beta}\)
</p>

<p>
And-elimination: \(\frac{\alpha\land\beta}{\alpha}\)
</p>

<p>
logical equivalences used as rules: \(\frac{\alpha\iff\beta}{(\alpha\implies\beta)\land(\beta\implies\alpha)}\)
</p>

<p>
all logical equivalence rewriting rules:
</p>

<p>
<img src="/Users/alex/Dropbox/vimwiki/img/is/logical-rewriting-rules.png" alt="Rewriting rules for logic" />
</p>

<div id="Logical agents-Calculus (algorithms for inference)-Proof methods-Rule-based reasoning-Searching for proofs"><h5 id="Searching for proofs">Searching for proofs</h5></div>
<p>
Finding proofs is like finding solutions to search problems.
</p>

<p>
monotonicity: set of entailed sentences can only increase as info is added to the knowledge base.
</p>
<ul>
<li>
for any sentence α and β,

<li>
if KB |= α, then KB ∧ β |= α

</ul>

<div id="Logical agents-Calculus (algorithms for inference)-Proof methods-Rule-based reasoning-Forward and backward chaining"><h5 id="Forward and backward chaining">Forward and backward chaining</h5></div>
<p>
FC is data-driven, automatic, unconscious:
</p>
<ul>
<li>
derive all facts entailed by the KB

<li>
may do lots of work irrelevant to the goal

</ul>

<p>
BC is goal-driven, appropriate for problem-solving
</p>
<ul>
<li>
specific fact entailed by the KB

<li>
complexity of BC can be much less than linear in size of KB

</ul>

<div id="Logical agents-Calculus (algorithms for inference)-Proof methods-Rule-based reasoning-Resolution"><h5 id="Resolution">Resolution</h5></div>
<p>
a rule is sound if its conclusion is evaluated to true whenever the premise is evaluated to true.
</p>

<p>
can be shown to be sound using truth table:
</p>

<p>
<img src="/Users/alex/Dropbox/vimwiki/img/is/sound-rules-inference.png" alt="Sound rules for inference" />
</p>

<p>
properties resolution:
</p>
<ul>
<li>
resolution rule is sound

<li>
resolution rule is complete (on its own) for formulas in CNF

<li>
resolution can only decide satisfiability

</ul>

<p>
algorithm (again proof by refutation):
</p>
<ol>
<li>
Convert KB ∧ ¬ α into CNF

<li>
Apply resolution rule to resulting clauses

<li>
Continue until:

<ol>
<li>
no new clauses can be added, hence α does not entail β

<li>
two clauses resolve to entail empty clause, hence α entails β

</ol>
</ol>

<div id="Probability and Uncertainty"><h1 id="Probability and Uncertainty">Probability and Uncertainty</h1></div>
<p>
one often has to deal with info that is underspecified, incomplete, vague, etc.
</p>

<p>
logic by itself is not sufficient for these problems.
</p>

<div id="Probability and Uncertainty-Vagueness: Fuzzy Set Theory"><h2 id="Vagueness: Fuzzy Set Theory">Vagueness: Fuzzy Set Theory</h2></div>
<p>
model theory often based on set theory
</p>

<p>
fuzzy set theory allows something to be <em>to some degree</em> an element of a set
</p>

<p>
dominant approach to vagueness (mostly because wtf else can you do)
</p>

<div id="Probability and Uncertainty-Vagueness: Fuzzy Set Theory-Fuzzy sets"><h3 id="Fuzzy sets">Fuzzy sets</h3></div>
<ul>
<li>
universe U, object x ∈ U

<li>
membership function for fuzzy set A is defined to be function \(f_A\) from U to [0,1]:

<ul>
<li>
\(f_A(x)=y\): x is a member of A to degree y

<li>
\(f_A(x)=1\): x is certainly member of A

<li>
\(f_A(x)=0\): x is certainly not a member of A

<li>
\({x | f_A(x)&gt;0}\): support of A

</ul>
</ul>

<p>
modifiers (hedges)
</p>

<p>
<img src="/Users/alex/Dropbox/vimwiki/img/is/modifiers-hedges.png" alt="Example of modifiers' effects on graphs" />
</p>

<p>
operations on fuzzy sets:
</p>
<ul>
<li>
complement: \(f_{\sim{A}}(x)=1-f_A(x)\)

<li>
union: \(f_{A\cup B}(x)=\max(f_A(x),f_B(x))\)

<li>
intersection: \(f_{A\cap B}(x)=\min(f_A(x), f_B(x))\)

<li>
subset: \(A\subset B \iff \forall{x}(f_A(x)\leq f_B(x))\)

</ul>

<p>
semantics -- multivalued fuzzy logic
</p>
<ul>
<li>
v(¬ A) = 1-v(A)

<li>
v(A ∨ B) = max(v(A), v(B))

<li>
v(A ∧ B) = min(v(A), v(B))

<li>
v(A → B) = min(1, 1 - v(A) + v(B))

</ul>

<div id="Probability and Uncertainty-Vagueness: Fuzzy Set Theory-Fuzzy relations"><h3 id="Fuzzy relations">Fuzzy relations</h3></div>
<p>
fuzzy sets can denote fuzzy relations between objects. e.g. approximately equal, close to, much larger than, etc.
</p>

<p>
fuzzy composition:
</p>

<p>
\(f_{R \circ S} (\langle x,z\rangle ) = \max_{y \in Y} \min(f_R (\langle x,y\rangle ), f_S (\langle y,z\rangle ))\)
</p>

<p>
hands-on example:
</p>

<p>
<img src="/Users/alex/Dropbox/vimwiki/img/is/fuzzy-composition.png" alt="Fuzzy composition table" />
</p>

<div id="Probability and Uncertainty-Vagueness: Fuzzy Set Theory-Evaluation"><h3 id="Evaluation">Evaluation</h3></div>
<ul>
<li>
good -- flexible, coincides with classical set theory, sever successful applications of fuzzy control

<li>
bad -- requires many arbitrary choices, tends to blur differences between probabilistic uncertainty/ambiguity/vagueness

</ul>

<div id="Probability and Uncertainty-Uncertainties: Probability Theory"><h2 id="Uncertainties: Probability Theory">Uncertainties: Probability Theory</h2></div>
<div id="Probability and Uncertainty-Uncertainties: Probability Theory-General"><h3 id="General">General</h3></div>
<p>
main interpretations of probability theory:
</p>
<ul>
<li>
optivist (frequentist) probability

<ul>
<li>
frequentism: probability is only property of repeated experiments

<li>
probability of event: limit of <em>relative frequency</em> of occurrence of event, as number of repetitions goes to infinity

</ul>
<li>
subjective probability

<ul>
<li>
Bayesianism: probability is an expression of our uncertainty and beliefs

<li>
probability of event: <em>degree of belief</em> of idealized rational individual

</ul>
</ul>

<p>
sample space Ω: set of single outcomes of experiment
</p>

<p>
event space E: things that have probability (subsets of sample space). if sample space is finite, event space is usually power set.
</p>

<div id="Probability and Uncertainty-Uncertainties: Probability Theory-Axioms of probability"><h3 id="Axioms of probability">Axioms of probability</h3></div>
<p>
for any event A, B:
</p>
<ul>
<li>
\(0 \leq P(A) \leq 1\)

<li>
\(P(\Omega) = 1\)

<li>
\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)

</ul>

<p>
can derive:
</p>
<ul>
<li>
\(P({}) = 0\)

<li>
\(P(\Omega) = 1\)

<li>
\(\text{if} A \subset B, P(A) \leq P(B)\)

</ul>

<p>
conditional probability ("A given B"):
</p>

<p>
\(P(A|B) = \frac{P(A \cap B)}{P(B)}\)
</p>

<div id="Probability and Uncertainty-Uncertainties: Probability Theory-Joint probability distributions"><h3 id="Joint probability distributions">Joint probability distributions</h3></div>
<p>
for a set of random variables, it gives probability of every atomic even on those random variables.
</p>

<p>
e.g. P(Toothache, Catch, Cavity):
</p>

<table>
<tr>
<th>
&nbsp;
</th>
<th colspan="2">
toothache
</th>
<th colspan="2">
¬ toothache
</th>
</tr>
<tr>
<td>
&nbsp;
</td>
<td>
catch
</td>
<td>
¬ catch
</td>
<td>
catch
</td>
<td>
¬ catch
</td>
</tr>
<tr>
<td>
cavity
</td>
<td>
0.108
</td>
<td>
0.012
</td>
<td>
0.072
</td>
<td>
0.008
</td>
</tr>
<tr>
<td>
¬ cavity
</td>
<td>
0.015
</td>
<td>
0.064
</td>
<td>
0.144
</td>
<td>
0.576
</td>
</tr>
</table>

<p>
inference by enumeration:
</p>
<ul>
<li>
for any proposition Φ, sum atomic events where it's true -- \(P(\Phi) = \sum_{\omega : \omega \models \Phi} P(\omega)\)

<li>
compute conditional probability by selecting cells -- e.g. for P(¬ cavity | toothache), select toothache column and (¬ cavity) cells

</ul>

<p>
use Bayes' rule for opposite conditionals (like finding P(disease | symptom) from P(symptom | disease))
</p>

<div id="Probability and Uncertainty-Uncertainties: Probability Theory-Bayesian networks"><h3 id="Bayesian networks">Bayesian networks</h3></div>
<p>
simple graphical notation for 
</p>
<ul>
<li>
conditional independence assertions

<li>
compact specification of full joint distributions

</ul>

<p>
syntax:
</p>
<ul>
<li>
set of nodes, one per variable

<li>
directed acyclic graph, with a link meaning "directly influences"

<li>
conditional distribution for each node given its parents -- \(P(X_i | Parents(X_i))\)

</ul>

<p>
topology example:
</p>

<p>
<img src="/Users/alex/Dropbox/vimwiki/img/is/bayesian-topology.png" alt="Bayesian network topology" />
</p>

<p>
what does it mean?
</p>
<ul>
<li>
<em>weather</em> is independent of other variables

<li>
<em>toothache</em> and <em>catch</em> are conditionally independent given <em>cavity</em>.

</ul>

<div id="Probability and Uncertainty-Uncertainties: Probability Theory-Evaluation of probabilities"><h3 id="Evaluation of probabilities">Evaluation of probabilities</h3></div>
<ul>
<li>
good -- sound theoretical basis, can be extended to decision-making, some good tools available

<li>
bad -- not always computationally easy, need lots of data which may be hard to get

</ul>


<div id="Machine Learning"><h1 id="Machine Learning">Machine Learning</h1></div>

<p>
design of a learning element is affected by:
</p>
<ul>
<li>
which components of performance element are to be learned

<li>
what feedback is available to learn these components

<li>
what representation is used for the components

</ul>

<p>
offline learning: learn based on some data, then apply results to situation
</p>

<p>
feedback types (get input, make decision, learn based on feedback):
</p>
<ul>
<li>
supervised learning: correct answers for each example.

<ul>
<li>
only positive examples

<li>
positive and negative examples

</ul>
<li>
unsupervised learning: no correct answers given

<li>
semi-supervised learning: learn which questions to ask (active learning)

<li>
reinforcement learning: occasional rewards

</ul>

<p>
<img src="/Users/alex/Dropbox/vimwiki/img/is/neurons-vs-nn.png" />
</p>

<div id="Machine Learning-Learning problems"><h2 id="Learning problems">Learning problems</h2></div>

<p>
Classification
</p>
<ul>
<li>
use: from data to discrete classes.

<li>
examples: handwriting recognition, spam filtering, facial recognition.

</ul>

<p>
Regression
</p>
<ul>
<li>
use: predicting a numeric value

<li>
examples: stock market, weather predictions

</ul>

<p>
Ranking
</p>
<ul>
<li>
use: comparing items

<li>
examples: web search

</ul>

<p>
Collaborative filtering
</p>
<ul>
<li>
use: take some else's information, based on that, give prediction

<li>
examples: recommendation systems (books, movies/shows)

</ul>

<p>
Clustering
</p>
<ul>
<li>
use: discovering structure/patterns in data

<li>
examples: clustering images

</ul>

<div id="Machine Learning-Methodology"><h2 id="Methodology">Methodology</h2></div>
<div id="Machine Learning-Methodology-Data"><h3 id="Data">Data</h3></div>
<p>
labeled instances (like spam, not spam)
</p>
<ul>
<li>
training set

<li>
held out set (e.g. for validation)

<li>
test set (don't even look at this until you want to test your model)

</ul>

<p>
randomly allocate to data sets.
</p>

<p>
features: attribute-value pairs characterizing each x
</p>

<div id="Machine Learning-Methodology-Experimentation"><h3 id="Experimentation">Experimentation</h3></div>
<p>
experimentation cycle:
</p>
<ol>
<li>
select hypothesis, tune hyperparameters on held-out/validation set

<li>
compute accuracy of test set (never "peek" at test set itself)

</ol>

<div id="Machine Learning-Methodology-Evaluation"><h3 id="Evaluation">Evaluation</h3></div>
<p>
accuracy -- fraction of instances predicted correctly
</p>

<p>
Cross validation:
</p>

<p>
<img src="/Users/alex/Dropbox/vimwiki/img/is/cross-validation.png" alt="Cross validation diagram" />
</p>

<p>
create a confusion matrix (<span class="todo">TODO</span>: there's a diagram for this but not in the old slides)
</p>

<div id="Machine Learning-ML Recipe:"><h2 id="ML Recipe:">ML Recipe:</h2></div>
<ol>
<li>
choose the features

<li>
choose the model class

<li>
choose a search method

</ol>

<div id="Machine Learning-ML Recipe:-Choose the features"><h3 id="Choose the features">Choose the features</h3></div>
<p>
create a feature space: features on x-y axes, points are individual data, classification would be a color scheme.
</p>

<p>
<img src="/Users/alex/Dropbox/vimwiki/img/is/feature-space.png" alt="Feature space graph" />
</p>


<div id="Machine Learning-ML Recipe:-Choose the features-Inductive learning method"><h4 id="Inductive learning method">Inductive learning method</h4></div>
<ul>
<li>
construct/adjust h to agree with f (function predicting value) on training set

<li>
h is consistent if it agrees with f on all examples

<li>
for example, curve fitting:
    <img src="/Users/alex/Dropbox/vimwiki/img/is/curve-fitting.png" alt="Curve fitting graph" />

</ul>

<p>
Occam's razor: "one should not increase, beyond what is necessary, the number of entities required to explain anything"
basically, choose the simplest option.
</p>

<p>
linear classifier: come up with a line that divides feature space, use that for prediction.
</p>

<div id="Machine Learning-ML Recipe:-Choose the features-Classifying with naive Bayes"><h4 id="Classifying with naive Bayes">Classifying with naive Bayes</h4></div>

<p>
Binary classification
</p>
<ul>
<li>
input: email

<li>
output: spam, not spam

<li>
setup:

<ul>
<li>
get large collection of example emails, labeled "spam/not spam"

<li>
someone has to hand-label that

<li>
want to learn to predict label for new emails in future

</ul>
<li>
features: attributes used to make label decision

<ul>
<li>
words, text patterns (e.g. caps), non-text

</ul>
</ul>

<p>
calculation for Bayesian classifier: \(P(C|F_1,...,F_n)\)
</p>

<p>
using Bayes' theorem:
</p>

<p>
\(P(C|F_1,...F_n)=\frac{P(C)P(F_1,...,F_n|C)}{P(F_1,...,F_n)}\)
</p>

<p>
rewrite the numerator of the equation:
</p>

\begin{align}
P(C)P(F_1,...,F_n |C)\\
= P(C)P(F_1 | C)P(F_2 | C, F_1)P(F_3|C, F_1, F_2)P(F_4,...,F_n | C, F_1, F_2, F_3)
\end{align}

<p>
that uses the chaining rule. but it's too computationally expensive.
so naively assume conditional independence:
</p>

\[
P(F_i | C, F_j) = P(F_i | C)
\]

<p>
This simplifies the formula to:
</p>

\[
P(C)P(F_1,...,F_n | C) = P(C) PI(0 to n) P(F_i | C)
\]

<p>
<img src="/Users/alex/Dropbox/vimwiki/img/is/bayes-calculation.png" />
</p>

<p>
Laplace smoothing helps with really small probabilities.
Naive Bayes often works. sometimes performs well even if the assumptions are badly violated.
classification is about predicting correct class label, <em>not</em> about accurately estimating probabilities
</p>

    </div>
</body>
</html>
